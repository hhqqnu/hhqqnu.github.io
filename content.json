[{"title":"前端基本知识整理","date":"2021-02-25T04:36:39.000Z","path":"2021/02/25/前端基本知识整理/","text":"重排(回流)reflow与重绘repaint 重排，当DOM元素位置或大小变化时，浏览器需要重新计算元素的几何属性，将元素放到正常的位置，这个过程就是重排。 重绘，当DOM元素的外观发生变化，但没有改变其布局，重新绘制元素外观的过程，叫做重绘。 重排与重绘次数过多会影响页面性能 减少次数方法，将同一元素的布局操作进行一次性改变。如：JS去操作元素top,left，此时就会产生2次。（尽量不要把读操作和写操作放在一个语句里，这样会产生2次或多次的重排重绘)。 对于有动画的元素，使用POSITION的ABSOLUTE或FIXED将其脱离文档,在实现动画时将不会影响到其他元素。","tags":[{"name":"javascript","slug":"javascript","permalink":"https://hhqqnu.github.io/tags/javascript/"},{"name":"typescript","slug":"typescript","permalink":"https://hhqqnu.github.io/tags/typescript/"},{"name":"react","slug":"react","permalink":"https://hhqqnu.github.io/tags/react/"},{"name":"vue","slug":"vue","permalink":"https://hhqqnu.github.io/tags/vue/"},{"name":"webpack","slug":"webpack","permalink":"https://hhqqnu.github.io/tags/webpack/"}]},{"title":"Hexo在Typora插入图片","date":"2021-02-25T01:42:03.000Z","path":"2021/02/25/Hexo在Typora插入图片/","text":"关于HEXO中插入图片,原来一直使用图床，由于免费的图床服务会停掉，导致文章图片会丢失,现决定使用本地嵌入图片的方式，虽然慢一点，但图片还在。 HEXO嵌入本地图片需要做如下操作： 安装图片插件 1npm install hexo-image-link --save 调整配置 12345678910111213# Writingnew_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: enable: true # Open external links in new tab field: site # Apply to the whole site exclude: &#x27;&#x27;filename_case: 0render_drafts: falsepost_asset_folder: true #设置为TRUErelative_link: falsefuture: true 由于使用的是Typora进行编辑Markdown文档，进行配置图片复制到指定的路径 创建POST和执行查看图片是否正常显示 1hexo clean &amp;&amp; hexo generate &amp;&amp; hexo server 发布 1hexo deploy 注：发布需要安装hexo-deployer-git依赖","tags":[{"name":"hexo","slug":"hexo","permalink":"https://hhqqnu.github.io/tags/hexo/"}]},{"title":"实现一个简单的代理服务器","date":"2020-03-24T13:01:59.000Z","path":"2020/03/24/实现一个简单的代理服务器/","text":"代理服务器概述代理服务器（Proxy Server）的功能是代理网络用户去取得网络信息。形象地说，它是网络信息的中转站，是个人网络和Internet服务商之间的中间代理机构，负责转发合法的网络信息，对转发进行控制和登记。 代理服务器作为连接Internet与Intranet的桥梁，在实际应用中发挥着极其重要的作用，它可用于多个目的，最基本的功能是连接，此外还包括安全性、缓存、内容过滤、访问控制管理等功能。更重要的是，代理服务器是Internet链路级网关所提供的一种重要的安全功能，它的工作主要在开放系统互联（OSI）模型的对话层 本次利用Go语言实现一个简单的HTTP代理服务器，主要分为以下几个部分完成： 实现简单的Web服务器 实现简单的代理服务器 手动实现 通过ini文件配置代理WEB对象 根据访问路径实现基本的代理服务器 实现代理服务器基本的Basic认证 使用go内置代理函数实现 实现代理服务器负载均衡 简单的随机负载 IP_HASH负载 负载加权随机 轮询负载 轮询加权 平滑轮询加权 负载均衡HTTPSERVER健康检查 简易健康检查 实现简单FailOver 实现简单的Web服务器使用Go的Http完成两个Web服务器并分别监听在9001和9002端口 123456789101112131415161718192021222324252627282930type web1Handler struct&#123;&#125;func (h web1Handler) ServeHTTP(writer http.ResponseWriter, request *http.Request) &#123; _, _ = writer.Write([]byte(&quot;WEB1&quot;))&#125;type web2Handler struct&#123;&#125;func (h web2Handler) ServeHTTP(writer http.ResponseWriter, request *http.Request) &#123; _, _ = writer.Write([]byte(&quot;WEB2&quot;))&#125;func main() &#123; c := make(chan os.Signal) go func() &#123; _ = http.ListenAndServe(&quot;:9001&quot;, web1Handler&#123;&#125;) &#125;() go func() &#123; _ = http.ListenAndServe(&quot;:9002&quot;, web2Handler&#123;&#125;) &#125;() signal.Notify(c, os.Interrupt) s := &lt;-c log.Println(s)&#125; 实现简单的代理服务器手动实现 通过ini文件配置代理WEB对象 创建env.ini文件用于存储所需要代理的WEB服务器列表 123456789[proxy][proxy.a]path=/apass=http://localhost:9001[proxy.b]path=/bpass=http://localhost:9002 读取配置文件，使用第三方依赖读取ini文件 1go get github.com/go-ini/ini 12345678910111213141516171819202122var ProxyConfigs map[string]stringtype EnvConfig *os.Filefunc init() &#123; ProxyConfigs = make(map[string]string) EnvConfig, err := ini.Load(&quot;env.ini&quot;) if err != nil &#123; fmt.Println(err) &#125; section, _ := EnvConfig.GetSection(&quot;proxy&quot;) if section != nil &#123; sections := section.ChildSections() for _, s := range sections &#123; path, _ := s.GetKey(&quot;path&quot;) pass, _ := s.GetKey(&quot;pass&quot;) if path != nil &amp;&amp; pass != nil &#123; ProxyConfigs[path.Value()] = pass.Value() &#125; &#125; &#125;&#125; 根据访问路径实现基本的代理功能 获取PrxoyConfigs配置项列表，循环获取对应的path及Web服务器访问路径 123456789for k, v := range ProxyConfigs &#123; fmt.Println(k,v) if matched, _ := regexp.MatchString(k, request.URL.Path); matched == true &#123; // 代理处理 RequestUrl(request, writer, v) return &#125;&#125;_, _ = writer.Write([]byte(&quot;defaut&quot;)) 实现代理服务器基本的Basic认证，主要是通过将原始的http request header头和http response header头原样返回给浏览器 Basic认证是一种较为简单的HTTP认证方式，客户端通过明文（Base64编码格式）传输用户名和密码到服务端进行认证，通常需要配合HTTPS来保证信息传输的安全 Basic认证会在Response Header中添加WWW-Authenticate标头，浏览器识别到Basic后弹出对话框Realm表示Web服务器中受保护文档的安全域 为WEB1服务器启用Basic认证 12345678910111213141516171819func (h web1Handler) ServeHTTP(writer http.ResponseWriter, request *http.Request) &#123; auth := request.Header.Get(&quot;Authorization&quot;) if auth == &quot;&quot; &#123; writer.Header().Set(&quot;WWW-Authenticate&quot;, `Basic realm=&quot;您必须输入用户名和密码&quot;`) writer.WriteHeader(http.StatusUnauthorized) return &#125; authList := strings.Split(auth, &quot; &quot;) if len(authList) == 2 &amp;&amp; authList[0] == &quot;Basic&quot; &#123; res, err := base64.StdEncoding.DecodeString(authList[1]) if err == nil &amp;&amp; string(res) == &quot;tom:123&quot; &#123; _, _ = writer.Write([]byte(fmt.Sprintf(&quot;web1,form ip:%s&quot;, GetIp(request)))) return &#125; &#125; _, _ = writer.Write([]byte(&quot;用户名或密码错误&quot;))&#125; 效果如下图： 代理服务器需要做的是输入头及输出头的复制。 12345func CloneHead(src http.Header, dest *http.Header) &#123; for k, v := range src &#123; dest.Set(k, v[0]) &#125;&#125; 代理服务器代理逻辑 1234567891011121314151617181920func RequestUrl(request *http.Request, writer http.ResponseWriter, url string) &#123; fmt.Println(request.RemoteAddr) newReq, _ := http.NewRequest(request.Method, url, request.Body) CloneHead(request.Header, &amp;newReq.Header) if ip := request.Header.Get(XForwardedFor); ip == &quot;&quot; &#123; newReq.Header.Add(XForwardedFor, request.RemoteAddr) &#125; response, _ := http.DefaultClient.Do(newReq) getHeader := writer.Header() CloneHead(response.Header, &amp;getHeader) writer.WriteHeader(response.StatusCode) defer response.Body.Close() c, _ := ioutil.ReadAll(response.Body) _, _ = writer.Write(c)&#125; 通过上面手动实现代理的方法，已对代理大体逻辑了解，那go是否已存在代理函数呢，答案是有的，直接利用httpUtil.NewSingleHostReverseProxy直接实现 1234567891011for k, v := range ProxyConfigs &#123; fmt.Println(k,v) if matched, _ := regexp.MatchString(k, request.URL.Path); matched == true &#123; target, _ := url.Parse(v) proxy := httputil.NewSingleHostReverseProxy(target) proxy.ServeHTTP(writer, request) // RequestUrl(request, writer, v) return &#125;&#125; 实现代理服务器负载均衡 负载均衡，英文名称为Load Balance，其含义就是指将负载（工作任务）进行平衡、分摊到多个操作单元上进行运行，例如上面建立的Web服务器、FTP服务器、企业核心应用服务器和其它主要任务服务器等，从而协同完成工作任务。 随机负载是通过随机算法从服务器列表中随机选取一台服务器进行访问。由概率论可以得知，随着客户端调用服务端的次数增多，其实际效果趋近于平均分配请求到服务端的每一台服务器，也就是达到轮询的效果。 为了查看效果方便，此处调整web服务器代码和写死web服务器访问地址到proxy中。 web服务器 123456789101112type web1Handler struct&#123;&#125;func (h web1Handler) ServeHTTP(writer http.ResponseWriter, request *http.Request) &#123; _, _ = writer.Write([]byte(&quot;web1&quot;))&#125;type web2Handler struct&#123;&#125;func (h web2Handler) ServeHTTP(writer http.ResponseWriter, request *http.Request) &#123; _, _ = writer.Write([]byte(&quot;web2&quot;))&#125; 添加LoadBalance 123456789101112131415161718192021222324252627282930313233343536package utilimport ( &quot;math/rand&quot; &quot;time&quot;)type HttpServer struct &#123; Host string&#125;type LoadBalance struct &#123; Servers []*HttpServer&#125;func NewHttpServer(host string) *HttpServer &#123; return &amp;HttpServer&#123; Host: host, &#125;&#125;func NewLoadBalance() *LoadBalance &#123; return &amp;LoadBalance&#123; Servers: make([]*HttpServer, 0), &#125;&#125;func (b *LoadBalance) AddServer(server *HttpServer) &#123; b.Servers = append(b.Servers, server)&#125;func (b *LoadBalance) SelectByRand() *HttpServer &#123; rand.Seed(time.Now().UnixNano()) index:=rand.Intn(len(b.Servers)) return b.Servers[index]&#125; 使用GO RAND函数进行随机选择HTTPSERVER 调整PROXY 123456789101112131415161718func (*ProxyHandler) ServeHTTP(writer http.ResponseWriter, request *http.Request) &#123; defer func() &#123; if err := recover(); err != nil &#123; writer.WriteHeader(500) _, _ = writer.Write([]byte(&quot;server error&quot;)) log.Println(err) &#125; &#125;() bl := NewLoadBalance() bl.AddServer(NewHttpServer(&quot;http://localhost:9001&quot;)) bl.AddServer(NewHttpServer(&quot;http://localhost:9002&quot;)) hostUrl, _ := url.Parse(bl.SelectByRand().Host) proxy := httputil.NewSingleHostReverseProxy(hostUrl) proxy.ServeHTTP(writer, request)&#125; 最终效果，访问本地http://localhost:8080，页面随机显示web1或web2内容 IP_HASH负载是根据请求所属的客户端IP计算得到一个数值，然后把请求发往该数值对应的后端。 所以同一个客户端的请求，都会发往同一台后端，除非该后端不可用了，所以IP_HASH能够达到保持会话的效果。 在GO中可以利用CRC算法(循环冗余校验)和术语算法实现。 123ip:=&quot;127.0.0.1&quot;fmt.Println(crc32.ChecksumIEEE([]byte(ip)))//根据IP计算输出:3619153832 添加根据IP获取HTTPSERVER方法 1234func (b *LoadBalance) SelectByIpHash(ip string) *HttpServer &#123; index := int(crc32.ChecksumIEEE([]byte(ip))) % len(b.Servers) return b.Servers[index]&#125; 调整PROXY为IP_HASH代理 123456ip := request.RemoteAddr//hostUrl, _ := url.Parse(bl.SelectByRand().Host)hostUrl, _ := url.Parse(bl.SelectByIpHash(ip).Host)proxy := httputil.NewSingleHostReverseProxy(hostUrl)proxy.ServeHTTP(writer, request) 最终效果,访问http://localhost:8080时，均会访问同一台服务器。 负载加权随机是在随机算法上，为HTTPSERVER添加权重，选择HTTPSERVER时，根据权重进行随机选择。 根据HTTPSERVER WERIGHT计算出权重所占数组的个数，权重较大的会占数组的个数均多，随机选择时，选中的概率较大。 调整LoadBalance 123456789101112131415161718192021222324252627// 添加WEIGHTtype HttpServer struct &#123; Host string Weight int&#125;// 初始化LOADBALANCE和SERVERINDICESvar BL *LoadBalancevar ServerIndices []intfunc init() &#123; BL = NewLoadBalance() BL.AddServer(NewHttpServer(&quot;http://localhost:9001&quot;, 5)) BL.AddServer(NewHttpServer(&quot;http://localhost:9002&quot;, 15)) for index, server := range BL.Servers &#123; if server.Weight &gt; 0 &#123; for i := 0; i &lt; server.Weight; i++ &#123; ServerIndices = append(ServerIndices, index) &#125; &#125; &#125; fmt.Println(ServerIndices)&#125; 调整PROXY使用随机加权 1234hostUrl, _ := url.Parse(BL.SelectByWeightRand().Host)proxy := httputil.NewSingleHostReverseProxy(hostUrl)proxy.ServeHTTP(writer, request) 最终效果,访问http://localhost:8080时，会有1比3的效果，因为现在设置权重是5和15 缺点：需要生一个数组切片用于对应HTTPSERVER列表，如果设置权重数值过大，会引起内存问题。 改良算法 根据权重计算取值区间 如权限设置为 5:2:1， 通过5,7(5+2),8(5+2+1) 得出HTTPSERVER选择区间值应为[0,5) [5,7) [7,8) 然后根据[0,8)之内取一个随机数，随机数落在哪个区间内，就是哪台HTTPSERVER 调整WEIGHT RAND方法 12345678910111213141516func (b *LoadBalance) SelectByWeightRand2() *HttpServer &#123; rand.Seed(time.Now().UnixNano()) sumList := make([]int, len(b.Servers)) sum := 0 for i := 0; i &lt; len(b.Servers); i++ &#123; sum += b.Servers[i].Weight sumList[i] = sum &#125; rad := rand.Intn(sum) // [) for index, value := range sumList &#123; if rad &lt; value &#123; return b.Servers[index] &#125; &#125; return b.Servers[0]&#125; 调整PROXY使用改良方法 123hostUrl, _ := url.Parse(BL.SelectByWeightRand2().Host)proxy := httputil.NewSingleHostReverseProxy(hostUrl)proxy.ServeHTTP(writer, request) 轮询负载是把来自用户的请求轮流分配给内部的服务器：从服务器1开始，直到服务器N，然后重新开始循环 调整LoadBalance Server列表，添加curIndex值用于计算当前是哪个HTTPSERVER 1234type LoadBalance struct &#123; Servers []*HttpServer CurIndex int //指向当前的服务器，默认是0&#125; 添加轮询算法 12345func (b *LoadBalance) RoundRobin() *HttpServer &#123; server := b.Servers[b.CurIndex] b.CurIndex = (b.CurIndex + 1) % len(b.Servers) return server&#125; 使用轮询算法 123hostUrl, _ := url.Parse(BL.RoundRobin().Host)proxy := httputil.NewSingleHostReverseProxy(hostUrl)proxy.ServeHTTP(writer, request) 最终效果，按顺序访问HTTPSERVER 如在做实现时发现，结果和预想不一致，查看是否有浏览器默认请求,如”/favicon.icon” 轮询加权 在轮询的基础上加上权重，与负载加权随机思路基本一致 添加轮询加权算法(用加权数组切片计算HTTPSERVER) 12345func (b *LoadBalance) RoundRobinByWeight() *HttpServer &#123; server := b.Servers[ServerIndices[b.CurIndex]] b.CurIndex = (b.CurIndex + 1) % len(ServerIndices) return server&#125; 使用轮询加权 123hostUrl, _ := url.Parse(BL.RoundRobinByWeight().Host)proxy := httputil.NewSingleHostReverseProxy(hostUrl)proxy.ServeHTTP(writer, request) 使用区间算法进行轮询加权 1234567891011121314151617func (b *LoadBalance) RoundRobinByWeight2() *HttpServer &#123; server := b.Servers[0] sum := 0 for i := 0; i &lt; len(b.Servers); i++ &#123; sum += b.Servers[i].Weight if b.CurIndex &lt; sum &#123; server = b.Servers[i] if b.CurIndex == sum-1 &amp;&amp; i != len(b.Servers)-1 &#123; b.CurIndex++ &#125; else &#123; b.CurIndex = (b.CurIndex + 1) % sum &#125; break &#125; &#125; return server&#125; 使用区间加权算法 123hostUrl, _ := url.Parse(BL.RoundRobinByWeight2().Host)proxy := httputil.NewSingleHostReverseProxy(hostUrl)proxy.ServeHTTP(writer, request) 平滑轮询加权 是用于解决原先轮询加权存在的必须使用完权重较高的HTTPSERVER压力过大的缺点，平滑轮询加权只要保证在总权重次数内，HTTPSERVER只要能够出现它的权重即可，无需顺序执行权重较高的HTTPSERVER，再执行权重低的HTTPSERVER。 算法是通过给HTTPSERVER添加CURWERIGHT值，初始值为HTTPSERVER WEIGHT,然后通过命中权重的HTTPSERVER减去总权重，第二次请求将CURWEIGHT加上原始权重，依次执行，直到HTTPSERVER WEIGHT均为0。 示例如下表： 权重 命中 命中后的权重 {s1:3,s2:1,s3:1}（初始化权重） s1(最大) {s1:-2,s2:1:s3:1} s1减去5 {s1:-2,s2:2,s3:2} s1要加3，其他加1 s2 {s1:1,:s2:-3,s3:2} s2减去5 {s1:4,s2:-2,s3:3} 同上 s1 {s1:-1,:s2:-2,s3:3} s1减去5 {s1:2,s2:-1,s3:4} 同上 s3 {s1:2,:s2:-1,s3:-1} s3减去5 {s1:5,s2:0,s3:0} s1 {s1:0,s2:0,s3:0} s1减去5 调整HTTPSERVER，添加CURWEIGHT 123456type HttpServers []*HttpServertype HttpServer struct &#123; Host string Weight int CurWeight int //默认为0&#125; 添加平滑轮询方法 1234567891011121314151617func (b *LoadBalance) RoundRobinByWeight3() *HttpServer &#123; for _, s := range b.Servers &#123; s.CurWeight = s.CurWeight + s.Weight &#125; sort.Sort(b.Servers) fmt.Println(b.Servers) max := b.Servers[0] max.CurWeight = max.CurWeight - SumWeight test := &quot;&quot; for _, s := range b.Servers &#123; test += fmt.Sprint(s.Host,s.CurWeight, &quot;,&quot;) &#125; fmt.Println(test) return max&#125; 负载均衡HTTPSERVER健康检查 简易健康检查 http服务定时检查，修改状态 使用HTTP中的HEAD请求方式进行检查，优点仅返回HTTP头，不返回HTTP BODY，避免BODY内容过多，传输量较小。 为HTTPSERVER添加STATUS属性 123456type HttpServer struct &#123; Host string Weight int CurWeight int //默认为0 Status string // 状态，默认UP，宕机DOWN&#125; 添加定时检查对象 1234567891011121314151617181920212223242526272829303132333435363738package utilimport ( &quot;net/http&quot; &quot;time&quot;)type HttpChecker struct &#123; Servers HttpServers&#125;func NewHttpChecker(servers HttpServers) *HttpChecker &#123; return &amp;HttpChecker&#123; Servers: servers, &#125;&#125;func (h *HttpChecker) Check(timeout time.Duration) &#123; client := http.Client&#123; Timeout: timeout, &#125; for _, s := range h.Servers &#123; res, err := client.Head(s.Host) if res != nil &#123; res.Body.Close() &#125; if err != nil &#123; s.Status = &quot;DOWN&quot; continue &#125; if res.StatusCode &gt;= 200 &amp;&amp; res.StatusCode &lt; 400 &#123; s.Status = &quot;UP&quot; &#125; else &#123; s.Status = &quot;DOWN&quot; &#125; &#125;&#125; 初始化服务器时调用检查对象 12345678910111213141516171819func checkServers(servers HttpServers) &#123; t := time.NewTicker(time.Second * 3) check := NewHttpChecker(servers) for &#123; select &#123; case &lt;-t.C: check.Check(time.Second * 2) for _, s := range servers &#123; fmt.Println(s.Host, s.Status) &#125; fmt.Println(&quot;---------------------&quot;) &#125; &#125;&#125;go func() &#123; checkServers(BL.Servers)&#125;() 最终检查效果,当关闭服务器时，标注HTTPSERVER STATUS为DOWN,启动后标注为UP 12345678910111213141516171819202122---------------------http://localhost:9001 UPhttp://localhost:9002 UPhttp://localhost:9003 UP---------------------http://localhost:9001 UPhttp://localhost:9002 DOWNhttp://localhost:9003 DOWN---------------------http://localhost:9001 UPhttp://localhost:9002 DOWNhttp://localhost:9003 DOWN---------------------http://localhost:9001 DOWNhttp://localhost:9002 DOWNhttp://localhost:9003 DOWN---------------------http://localhost:9001 UPhttp://localhost:9002 UPhttp://localhost:9003 UP--------------------- 实现简单FailOver结合健康检查，处理有问题的HTTPSERVER 计数器算法 为HTTPSERVER添加FAILCOUNT和SUCCESSCOUNT属性， 为HTTPCHECKER添加FAILMAX和RECOVERCOUNT属性 12345678910111213141516171819202122type HttpServer struct &#123; Host string Weight int CurWeight int //默认为0 Status string // 状态，默认UP，宕机DOWN FailCount int //出错次数 0 SuccessCount int&#125;type HttpChecker struct &#123; Servers HttpServers FailMax int RecoverCount int&#125;func NewHttpChecker(servers HttpServers) *HttpChecker &#123; return &amp;HttpChecker&#123; Servers: servers, FailMax: 6, RecoverCount: 3, //连续成功，到达这个值，标记UP &#125;&#125; HTTPCHECKER添加失败和成功方法处理方法 12345678910111213141516171819202122func (h *HttpChecker) Fail(server *HttpServer) &#123; if server.FailCount &gt;= h.FailMax &#123; server.Status = &quot;DOWN&quot; &#125; else &#123; server.FailCount++ &#125; server.SuccessCount = 0&#125;func (h *HttpChecker) Success(server *HttpServer) &#123; if server.FailCount &gt; 0 &#123; server.FailCount-- server.SuccessCount++ if server.SuccessCount == h.RecoverCount &#123; server.FailCount = 0 server.Status = &quot;UP&quot; server.SuccessCount = 0 &#125; &#125; else &#123; server.Status = &quot;UP&quot; &#125;&#125; 普通轮询添加FAILOVER机制 注意全部服务器都DOWN了 1234567891011121314151617181920212223// 检查所有服务器状态是否DOWNfunc (b *LoadBalance) IsAllDown() bool &#123; downCount := 0 for _, s := range b.Servers &#123; if s.Status == &quot;DOWN&quot; &#123; downCount++ &#125; &#125; if downCount == len(b.Servers) &#123; return true &#125; return false&#125;// 普通轮询func (b *LoadBalance) RoundRobin() *HttpServer &#123; server := b.Servers[b.CurIndex] b.CurIndex = (b.CurIndex + 1) % len(b.Servers) // 递归查询 if server.Status == &quot;DOWN&quot; &amp;&amp; !b.IsAllDown() &#123; return b.RoundRobin() &#125; return server&#125; 普通加权轮询出错降权处理，为HTTPSERVER增加降权权重值FAILWEIGHT，FAILWEIGHT是由当前FAILWEEIGHT+=WEIGHT*(1/FailFactor降权因子)得到，然后在获取服务器时真正的权重为WEIGHT-FAILWEIGHT，如果为0则代理此服务器为DOWN，在健康检查HTTPSERVER成功，则FAILWEIGHT直接设置为0 添加加权轮询FAILOVER 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879type HttpServer struct &#123; Host string Weight int CurWeight int //默认为0 FailWeight int //降低的权重 Status string // 状态，默认UP，宕机DOWN FailCount int //出错次数 0 SuccessCount int&#125;type HttpChecker struct &#123; Servers HttpServers FailMax int RecoverCount int FailFactor float64 //降权因子，默认是5.0&#125;func (h *HttpChecker) Fail(server *HttpServer) &#123; if server.FailCount &gt;= h.FailMax &#123; server.Status = &quot;DOWN&quot; &#125; else &#123; server.FailCount++ &#125; server.SuccessCount = 0 fw := int(math.Floor(float64(server.Weight)) * (1 / h.FailFactor)) if fw == 0 &#123; fw = 1 &#125; server.FailWeight += fw if server.FailWeight &gt; server.Weight &#123; server.FailWeight = server.Weight &#125;&#125;func (h *HttpChecker) Success(server *HttpServer) &#123; if server.FailCount &gt; 0 &#123; server.FailCount-- server.SuccessCount++ if server.SuccessCount == h.RecoverCount &#123; server.FailCount = 0 server.Status = &quot;UP&quot; server.SuccessCount = 0 &#125; &#125; else &#123; server.Status = &quot;UP&quot; &#125; server.FailWeight = 0&#125;// 区间算法func (b *LoadBalance) RoundRobinByWeight2() *HttpServer &#123; server := b.Servers[0] sum := 0 for i := 0; i &lt; len(b.Servers); i++ &#123; // 判断降权权重是否为0, 为0则代表服务器不可用 realWeight := b.Servers[i].Weight - b.Servers[i].FailWeight if realWeight == 0 &#123; continue &#125; //sum += b.Servers[i].Weight sum += realWeight if b.CurIndex &lt; sum &#123; server = b.Servers[i] if b.CurIndex == sum-1 &amp;&amp; i != len(b.Servers)-1 &#123; b.CurIndex++ &#125; else &#123; b.CurIndex = (b.CurIndex + 1) % sum &#125; break &#125; else &#123; b.CurIndex = 0 &#125; &#125; return server&#125; 平滑加权轮询FAILOVER与普通轮询加权基本一致，只需在平滑加权方法里面得到真正的权重 1234567891011121314151617181920212223242526272829303132333435func (b *LoadBalance) getSumWeight() int &#123; sum := 0 for _, s := range b.Servers &#123; realWeight := s.Weight - s.FailWeight if realWeight &gt; 0 &#123; sum += realWeight &#125; &#125; return sum&#125;func (b *LoadBalance) RoundRobinByWeight3() *HttpServer &#123; for _, s := range b.Servers &#123; s.CurWeight = s.CurWeight + s.Weight - s.FailWeight //得到真正的权重 &#125; sort.Sort(b.Servers) fmt.Println(b.Servers) max := b.Servers[0] // max.CurWeight = max.CurWeight - SumWeight max.CurWeight = max.CurWeight - b.getSumWeight() test := &quot;&quot; for _, s := range b.Servers &#123; test += fmt.Sprint(s.Host, s.CurWeight, &quot;,&quot;) &#125; fmt.Println(test) return max&#125;","tags":[{"name":"Go","slug":"Go","permalink":"https://hhqqnu.github.io/tags/Go/"}]},{"title":"记一次C#框架封装及性能优化","date":"2019-12-13T12:10:23.000Z","path":"2019/12/13/记一次C-框架封装及性能优化/","text":"本次框架封装主要是针对微软域控活动目录的基本操作。C#原先以提供活动目录的基本操作，但由域控本身概念较多，开发人员需要对其比较了解，为了降低这方面的学习成本，对其进行二次封装。 框架主要是针对如下两个方面进行封装： LDAP查询语句自动的生成 活动目录实体对象的操作 在阐述前，先来让我们简单了解关于域控的基本知识。 域控服务器域控服务器是用语言软件集中管理的器件，能安全集中管理域中账户密码、管理策略等构成数据库，统一安全策略。 域服务器的作用是： 安全集中管理，统一安全策略。 软件集中管理，按照公司要求限定所有机器只能运行必需的办公软件。 环境集中管理，利用AD可以统一客户端桌面,IE,TCP/IP等设置 活动目录是企业基础架构的根本，为公司整体统一管理做基础。其它ISA,Exchange,防病毒服务器，补丁分发服务器，文件服务器等服务依赖于域服务器。 原生操作1234567891011121314151617var path = &quot;LDAP://contoso.com&quot;;var userName = &quot;contoso\\\\administrator&quot;;var password = &quot;xxxxxx&quot;;using (var entry = new DirectoryEntry(path, userName, password))using (var searcher = new DirectorySearcher(entry))&#123; searcher.PageSize = 10000; searcher.Filter = &quot;(&amp;(objectClass=User))&quot;; searcher.SearchScope = SearchScope.Subtree; var searchResultCollection = searcher.FindAll(); foreach (SearchResult searchResult in searchResultCollection) &#123; var distinguishedName = searchResult.Properties[&quot;distinguishedName&quot;][0].ToString(); var objectClass = searchResult.Properties[&quot;ObjectClass&quot;][0].ToString(); &#125;&#125; 封装后操作123456var localAdOperation = new AdOperationBuilder().BuilderLocalAdOperation();var query = LdapQueryBuilder.Query() .Where(AdFieldNameConstant.ObjectClass).Is(&quot;User&quot;) .Filter().Encode();var adUsers = localAdOperation.GetEntities&lt;AdUser&gt;(query, AdFieldNameConstant.DisplayName);Console.WriteLine(adUsers.Count); 设计思路从以上的原生操作和封装后操作，很容易看出开发人员只需要生成LDAP语句，无需再去学习比较复杂的LDAP语法(与，或，非等)如: 1(&amp;(objectClass=User)) 所以本次封装的目标是简单，容易上手且无需关心域控活动目录实体对象属性，仅需根据实际开发要求获取对应的用户，组，组织单或其他。另有特殊要求可在项目中简单扩展即可完成所对应的操作。 看一下总体UML图： 框架主要分为多域控服务器配置封装，LDAP语句生成，每个实体对象生成查询，修改和删除。 性能问题由于本人比较喜欢TDD的开发模式，所以在每个功能点都会有相应的单元测试及功能测试，且域控活动目录原先查询有些慢，再加上有分页的封装，就没有加强测试性能这一块。 但在实际项目中使用发现查询速度差强人意。查询整个活动目录的ObjectClass=User的对象，查询时间结果如下图(既然花了这么久，有点惊讶)： 性能排查过程为了让查询比较方便，采用了数据转换实体的方法即反射技术。 所以想到是否由于元素过多，反射赋值或查询属性导致，决定第一步将反射类型对象进行缓存，利用C#表达式委托方法进行赋值和查询属性，而不使用反射进行赋值及查询属性值，但在做完这一步动作后，发现效果并不是很理想。第二步决定用trace进行跟踪测试程序运行，查看那一步引起性能问题。 跟踪到C#提供的原生获取属性的方法占用时间比较多，但原生方法无法改造，只能减少获取实体对象属性（根数据库查询不使用*一样的原理）。 现在放在面前只有减少属性的获取，但如果这样的话，调用端操作就比较麻烦，查询时需要知道有哪些属性字段（字段名的获取不向数据库来得那么方便），比较麻烦。 难道真的没有办法再优化了么？还是本身封装时就存在方法错误，此时抛弃认为正确的设计，采用原生方法进行测试，并获取相同的属性，发现测试性能并没有那么差。 会奇怪的发现和封装的方法里面调用不太一样，里面并没有把大多时间放在SearchResultCollection.get_Item方法上，而是在MoveNext上。从这个方法可以联想到封装为了能够用到InvokeGet方法，直接使用了SearchResult.GetDirectoryEntry方法。 为什么这个方法会引起性能问题呢，让我们接着往下看。 看到这一行有Bind方法，那Bind方法有什么呢，Bind方法里面调用了一个COM组件原生方法ADsOpenObject，这个原方法虽然看不到更多详细信息，但从中看到PATH,USERNAME,PASSWORD，可以猜测到这是又一次到服务器中进行获取数据。 性能优化通过上述的分析可以总结到封装在每一次获取数据特殊赋值时，原生方法会再一次去服务器获取数据，所以导致查询性能慢的原因。所以将无需调用InvokeGet方法的属性将不进行使用GetDirectory方法，直接使用SearchResult.Properties属性获取其值，最终测试如下图。 总结封装一个框架除了要简单，易用，示例，文档，性能也很重要的一部分，如性能不行框架也是无法使用，就像当年LINQ To SQL刚出来还是比较新颖的，但使用后发现数据库中数据比较多时会比较慢，所以放弃使用，再到微软也重新设计数据库ORM框架EF，可以看到性能是必备条件。","tags":[{"name":"C#","slug":"C","permalink":"https://hhqqnu.github.io/tags/C/"}]},{"title":"实现最简单的NodeJS Server","date":"2019-01-10T14:00:00.000Z","path":"2019/01/10/实现最简单的NodeJS-Server/","text":"","tags":[{"name":"javascript","slug":"javascript","permalink":"https://hhqqnu.github.io/tags/javascript/"},{"name":"nodejs","slug":"nodejs","permalink":"https://hhqqnu.github.io/tags/nodejs/"}]},{"title":"ES6 基本特性","date":"2018-04-20T12:22:59.000Z","path":"2018/04/20/ES6-基本特性/","text":"环境准备 - 编译ES6ES6特性不是所有的浏览器都支持，所以需要通过对ES6语法的编译。JAVASCRIPT打包处理方式有很多,Grunt,Gulp,Webpack,Rollup,这些都是针对于现在前端模块化开发而产生的。 Webpack是一个现代 JavaScript 应用程序的静态模块打包器(module bundler)。当 webpack 处理应用程序时，它会递归地构建一个依赖关系图(dependency graph)，其中包含应用程序需要的每个模块，然后将所有这些模块打包成一个或多个 bundle. ES6的编译采用WEBPACK+BABEL LOADER进行.在BABEL中可以使用BABEL PRESETS来控制编译后的浏览器支持。 Babel Presets optsions: targets、targets.browsers、targets.browsers: ‘last 2 version’、target.browsers: ‘&gt; 1%’这些浏览器的控制在browserslist或Can i use 网站可以查找。 环境准备步骤如下： install nodejs npm init -y npm install webpack -g npm install webpack babel-loader babel-core babel-preset-evn –save-dev add webpack.config.js webpack || package.json定义npm scripts命令 基本语法变量和常量 let 允许声明在范围内的变量，使用其上使用的块、语句或表达式。不同于var关键字，定义全局变量或者局部定义，而不考虑块范围。 示例代码： 12345678910111213141516171819function varTest() &#123; var x = 1; if (true) &#123; var x = 2; // same variable! console.log(x); // 2 &#125; console.log(x); // 2&#125;function letTest() &#123; let x = 1; if (true) &#123; let x = 2; // different variable console.log(x); // 2 &#125; console.log(x); // 1&#125; const const是块范围内定义的变量。通过定义分配一个常量不能改变值，且不能重定义,常量必须初始化. 1234567891011const number = 42;try &#123; number = 99;&#125; catch(err) &#123; console.log(err); // expected output: TypeError: invalid assignment to const `number&#x27; // Note - error messages will vary depending on browser&#125;console.log(number); 解构赋值解构赋值语法是一个JavaScript表达式，可以将值从数组，或从对象的属性，分为不同的变量。 123456789101112131415var a, b, rest;[a, b] = [10, 20];console.log(a);// expected output: 10console.log(b);// expected output: 20[a, b, ...rest] = [10, 20, 30, 40, 50];console.log(rest);// expected output: [30,40,50] 正则扩展 正则表达式是javascript操作字符串的一个重要组成部分，但在以往的版本中并未有太多改变。在ES6中，随着字符串操作的变更， ES6也对正则表达式进行了一些更新。 构造函数 在ES5中，RegExp构造函数的参数有两种情况。1、 参数是字符串，第二个参数为正则表过式修饰符。2、 参数为一个正则表达式，没有第二个参数 12345var regex = new RegExp(&#x27;xyz&#x27;,&#x27;i&#x27;);var regex = new RegExp(/xyz/i);var regex = /xyz/i; 在ES6中，RegExp构造函数为正则表达式时，允许提供第二参数，第二个参数则会替换原有的正则表达式修饰符。会在返回值里flags,值为替换后的正则表达式修饰符。 1234var regex = new RegExp(/xyz/ig,&#x27;i&#x27;)console.log(regex.flags) u修改符 正则表达式可以完成简单的字符串操作，但默认将字符串中的每一个字符按照16位编码处理。为了解决这个问题， ES6 对正则表达式添加了u修饰符，含义为“Unicode模式”，用来正确处理大于\\uFFFF的 Unicode 字符。也就是说，会正确处理四个字节的 UTF-16 编码。 12console.log(/^\\uD83D/u.test(&#x27;\\uD83D\\uDC2A&#x27;));console.log(/^\\uD83D/.test(&#x27;\\uD83D\\uDC2A&#x27;)); 点号 点（.）字符在正则表达式中，含义是除了换行符以外的任意单个字符。对于码位大于0xFFFF的 Unicode 字符，点字符不能识别，必须加上u修饰符 123456var text = &quot;𠮷&quot; ;console.log(text.length); // 2console.log(/^.$/.test(text));//falseconsole.log(/^.$/u.test(text)); //true 大括号 ES6 新增了使用大括号表示 Unicode 字符，这种表示法在正则表达式中必须加上u修饰符，才能识别当中的大括号，否则会被解读为量词。 12345console.log(/\\u&#123;61&#125;/.test(&#x27;a&#x27;));console.log(/\\u&#123;61&#125;/u.test(&#x27;a&#x27;));console.log(/\\u&#123;20BB7&#125;/u.test(&#x27;𠮷&#x27;)) 量词 使用u修饰符后，所有量词都会正确识别码点大于0xFFFF的 Unicode 字符 123456console.log(/a&#123;2&#125;/.test(&#x27;aa&#x27;));console.log(/a&#123;2&#125;/u.test(&#x27;aa&#x27;));console.log(/𠮷&#123;2&#125;/.test(&#x27;𠮷𠮷&#x27;));console.log(/𠮷&#123;2&#125;/u.test(&#x27;𠮷𠮷&#x27;)); y修饰符 除了u修饰符，ES6 还为正则表达式添加了y修饰符，叫做“粘连”（sticky）修饰符。y修饰符的作用与g修饰符类似，也是全局匹配，后一 次匹配都从上一次匹配成功的下一个位置开始。不同之处在于，g修饰符只要剩余位置中存在匹配就可，而y修饰符确保匹配必须从剩余的第一个位置开始，这也就是“粘连”的涵义。 1234567891011let s = &#x27;bbb_bb_b&#x27;;let r1 = /bb+/g;let r2 = /bb+/y;console.log(&#x27;r1 sticky:&#x27;, r1.sticky);console.log(&#x27;r2 sticky:&#x27;, r2.sticky);console.log(&#x27;f:&#x27;, r1.exec(s));console.log(&#x27;f:&#x27;, r2.exec(s));console.log(&#x27;s:&#x27;, r1.exec(s));console.log(&#x27;s:&#x27;, r2.exec(s)); 字符串扩展 字符串识别在原来indexOf方法识别后，ES6添加了includes,startsWith,endsWith includes 该方法在给定文本存在于字符串中的任意位置时会返回 true ，否则返回false。 startsWith 该方法在给定文本出现在字符串起始处时返回 true ，否则返回 false。 endsWith 该方法在给定文本出现在字符串结尾处时返回 true ，否则返回 false。 1234let msg = &#x27;test content&#x27;;console.log(msg.startsWith(&#x27;test&#x27;)); repeat ES6为字符串添加了一个 repeat() 方法，它接受一个参数作为字符串的重复次数，返回一个将初始字符串重复指定次数的新字符串 123console.log(&#x27;test &#x27;.repeat(3)); 字符串补全 针对某个字符串不够指定长度，会在头部或尾部补全。 padStart (头部补全)和padEnd(尾部补全)接受两个参数，第一个为字符串长度，第二个为需要补全的字符串。 123console.log(&#x27;t&#x27;.padStart(3,&#x27;1&#x27;)); 字符串模板 模板字面量是增强版的字符串，它用反引号（`）标识。 12345let name = &#x27;tom&#x27;;let message = `Hello,$&#123;name&#125;`;console.log(message); 数组扩展ES6为了简化数组操作，添加了很多新功能。 静态方法 Array.of (数组创建) 123456let a1 = Array.of(1, 2, 3, 4)console.log(a1)let a2 = Array.of(a1, 1, 2, 3, 4)console.log(a2) Array.from (数组创建) 1234console.log(Array.from(&#x27;foo&#x27;))console.log(Array.from([1, 2, 3], x =&gt; x + x)) includes (数组判断) 1234567var array1 = [1, 2, 3]console.log(array1.includes(2))var pets = [&#x27;cat&#x27;, &#x27;dog&#x27;, &#x27;bat&#x27;]console.log(pets.includes(&#x27;cat&#x27;))console.log(pets.includes(&#x27;at&#x27;)) find &amp; findIndex (数组查找,find是查找并返回 第一个查找到的值，findIndex是查找并返回第一个值的索引) 1234567891011var array1 = [5, 12, 8, 130, 44]var found = array1.find(function (element) &#123; return element &gt; 10&#125;);var foundIndex = array1.findIndex((ele)=&gt;&#123; return ele &gt; 10;&#125;);console.log(`found value:$&#123;found&#125;,index:$&#123;foundIndex&#125;`) fill (数组数据重写) 123456var array1 = [1, 2, 3, 4];console.log(array1.fill(0,2,4));console.log(array1.fill(5,1));console.log(array1.fill(6)); copyWithin (改变数组中的多个元素，值从本数组中进行复制) 12345var array1 = [1, 2, 3, 4, 5];console.log(array1.copyWithin(0, 3, 4));console.log(array1.copyWithin(1, 3)); 函数扩展函数在javascript中是重要组成部分，在ES6中添加了很多特性，使用函数使用更新灵活。 形参默认值 12345678let connetionSql = (connStr,timeOut=1000) =&gt; &#123; console.log(`connstr:$&#123;connStr&#125; timeout:$&#123;timeOut&#125;`);&#125;connetionSql(&#x27;mysql:///&#x27;);connetionSql(&quot;mysql:///&quot;,2000); 不定参数 虽然arguments对象来检查函数的所有参数，不必定义要用的参数，但arguments使用起来不是很方便。 1234567891011121314151617181920212223242526272829303132333435// es5let pick = function (obj) &#123;let result = Object.create(null)for (let i = 1; i &lt; arguments.length; i++) &#123; console.log(arguments[i]) result[arguments[i]] = obj[arguments[i]]&#125;return result&#125;let book = &#123; title: &#x27;ES6&#x27;, year: 2017, price: 50&#125;let bookData = pick(book, &#x27;title&#x27;, &#x27;year&#x27;)console.log(bookData)//ES 6let pick = function pick (object, ...keys) &#123; let result = Object.create(null) for (let i = 0, len = keys.length; i &lt; len; i++) &#123; result[keys[i]] = object[keys[i]] &#125; return result&#125;let book = &#123; title: &#x27;ES6&#x27;, year: 2017, price: 50&#125;let bookData = pick(book, &#x27;title&#x27;, &#x27;year&#x27;)console.log(bookData) 箭头函数 箭头函数是函数最有趣的特性，顾名思义，箭头函数是一种使用箭头(=&gt;)定义函数的新语法，但是它与传统的JS函数有些许不同，主要集中在以下方面: 没有this、super、arguments和new.target绑定箭头函数中的this、super、arguments和new.target这些值由外围最近一层非箭头函数决定 不能通过NEW关键字调用,箭头函数没有[[construct]]方法，不能被用作构造函数，如果通过new关键字调用箭头函数，程序抛出错误 没有原型,由于不可以通过new关键字调用箭头函数，因而没有构建原型的需求，所以箭头函数不存在prototype这个属性 不可以改变this绑定,函数内部的this值不可被改变，在函数的生命周期内始终保持一致 不支持arguments对象,箭头函数没有arguments绑定，必须通过命名参数和不定参数这两种形式访问函数的参数 不支持重复的命名参数,无论在严格还是非严格模式下，箭头函数都不支持重复的命名参数；而在传统函数的规定中，只有在严格模式下才不能有重复的命名参数 在箭头函数内，其余的差异主要是减少错误以及理清模糊不清的地方。JS引擎就可以更好地优化箭头函数的执行过程,这些差异的产生有如下原因: this绑定是JS程序中一个常见的错误来源，在函数内很容易对this的值失去控制，其经常导致程序出现意想不到的行为，箭头函数消除了这方面的烦恼 如果限制箭头函数的this值，简化代码执行的过程，则JS引擎可以更轻松地优化这些操作，而常规函数往往同时会作为构造函数使用或者以其他方式对其进行修改 12345678910111213141516171819202122var materials = [ &#x27;Hydrogen&#x27;, &#x27;Helium&#x27;, &#x27;Lithium&#x27;, &#x27;Beryllium&#x27;]console.log(materials.map(material =&gt; material.length))let sum = (num1, num2) =&gt; &#123; return num1 + num2&#125;console.log(sum(10, 20))let f = ([a, b] = [1, 2], &#123; x: c&#125; = &#123; x: a + b&#125;) =&gt; a + b + c;console.log(f()); 对象扩展 - 指OBJECT随着JS应用复杂度的不断增加，程序中使用对象的数量持续增长，ES6为了提升对象使用效率,通过多种方式来加强对象的使用，简单的语法扩展和更多操作对象及与对象交互的方法。 简洁表达式 属性初始值简写 123456789101112// ES5var name = &#x27;javascript es6&#x27;;var price = 50;var bookInfo = &#123; name: name, price: price&#125;;//console.log(bookInfo);//ES6var bookInfoEs6 = &#123;name,price&#125;;console.log(bookInfoEs6); 对象方法简写 123456789101112131415161718// ES5var people = &#123; name: &#x27;zhangsan&#x27;, say: function () &#123; console.log(&#x27;hello &#x27;,this.name); &#125;&#125;//people.say();//ES6var peopleEs6 = &#123; name: &#x27;zhangsan es6&#x27;, say () &#123; console.log(&#x27;hello &#x27;,this.name) &#125;&#125;peopleEs6.say(); 属性表达式 12345678910111213141516// ES5var name = &#x27;javascript es6&#x27;var price = 50var bookInfo = &#123; name: name, price: price&#125;//console.log(bookInfo[&#x27;name&#x27;],bookInfo[&#x27;price&#x27;]);//ES6let priceField = &#x27;price&#x27;var bookInfoEs6 = &#123; name: name, [priceField]: price, [&#x27;sale&#x27; + priceField]: price + 10&#125;console.log(bookInfoEs6[priceField], bookInfoEs6[&#x27;sale&#x27; + priceField]) Object 新增方法 判断相等 - Object.is()用于确定两个值是否相同。 123456789//ES5console.log(5 == 5);console.log(5 == &#x27;5&#x27;);console.log(5 === &#x27;5&#x27;);//ES6console.log(Object.is(5,5));console.log(Object.is(5,&#x27;5&#x27;)); 对象合并 - Object.assign() object.assign()方法用于将所有可枚举属性的值从一个或多个源对象复制到目标对象。它将返回目标对象。 1234567const object1 = &#123; a: 1, b: 2, c: 3&#125;const object2 = Object.assign(&#123;c: 4, d: 5&#125;, object1);console.log(object2); Object.entries() 返回给定对象自己的可枚举属性(键值)对的数组。 123456let test = &#123;k: 123,o: 456&#125;for (let [key, value] of Object.entries(test)) &#123; console.log(key, value)&#125; Set &amp;&amp; Map SET SET是一个无重复元素的集合列表。 1234567891011121314//声明操作const set1 = new Set([1, 2, 3, 4, 5])console.log(set1)console.log(set1.has(2))console.log(set1.has(6))set1.add(6)console.log(set1)set1.delete(3)console.log(set1)console.log(set1.keys())// converting between set and arrayconsole.log([...set1]) WeakSet WeakSet允许在集合中存储弱保存的对象。WeakSet与Set的区别在于WeakSet仅可以存储对象。 1234let weakSet = new WeakSet();let arg = &#123;&#125;;weakSet.add(arg);console.log(weakSet); Map Map对象持有键值对。任何值(对象和原始值)都可以用作键或值。 1234567891011let map = new Map()let arr = [&#x27;123&#x27;]map.set(arr, 456)console.log(&#x27;map&#x27;, map, map.get(arr))let map2 = new Map([[&#x27;a&#x27;, 123], [&#x27;b&#x27;, 456]])console.log(map2)map2.forEach((item, key) =&gt; &#123; console.log(key, item)&#125;) WeakMap WeakMap是键/值对的集合，其中的键是弱引用的。键必须是对象，值可以是任意值。 Proxy &amp;&amp; Reflect Proxy Proxy用于定义基本操作的自定义行为(例如属性查找、赋值、枚举、函数调用等) 123456789101112131415161718192021let bookInfo = &#123; name: &#x27;javascript ES6&#x27;, price: 50&#125;let mointor = new Proxy(bookInfo, &#123; get(target, key) &#123; if (key === &#x27;price&#x27;) &#123; return &#x27;$&#x27; + target[key] &#125; return key in target ? target[key] : &#x27;undefined&#x27; &#125;, set(target, key, value) &#123; if (key === &#x27;price&#x27; &amp;&amp; Number.isInteger(value)) &#123; target[key] = value &#125; &#125;&#125;)console.log(mointor.price)console.log(mointor.name)mointor.price = 100console.log(mointor.price) Reflect Reflect是一个内置的对象，它提供了用于拦截JavaScript操作的方法。这些方法与代理处理程序的方法相同。反射不是一个函数对象，所以它不是可构造的。 1234567let bookInfo = &#123; name: &#x27;javascript ES6&#x27;, price: 50&#125;console.log(Reflect.get(bookInfo, &#x27;name&#x27;)) 实例 1234567891011121314151617181920212223242526272829303132333435363738function validator (target, validator) &#123; return new Proxy(target, &#123; _validator: validator, set(target, key, value, proxy) &#123; if (target.hasOwnProperty(key)) &#123; let va = this._validator[key] if (!!va(value)) &#123; return Reflect.set(target, key, value) &#125; else &#123; throw Error(`$&#123;key&#125;设置值错误`) &#125; &#125; else &#123; throw Error(`$&#123;key&#125; 不存在`) &#125; &#125; &#125;)&#125;const personValidators = &#123; name(val) &#123; return typeof val === &#x27;string&#x27; &#125;, age(val) &#123; return typeof val === &#x27;number&#x27; &#125;&#125;class Person &#123; constructor (name, age) &#123; this.name = name this.age = age return validator(this, personValidators) &#125;&#125;const person = new Person(&#x27;zhangsan&#x27;, 30)console.log(person)person.age = &#x27;1111&#x27; 类与对象类声明使用基于原型的继承创建一个具有给定名称的新类。 基本语法 12345678class Parent &#123; constructor (name = &#x27;zhangsan&#x27;) &#123; this.name = name &#125;&#125;let parent = new Parent(&#x27;lisi&#x27;)console.log(parent) 类的继承 123456789101112131415class Parent &#123; constructor (name = &#x27;zhangsan&#x27;) &#123; this.name = name &#125;&#125;class Child extends Parent &#123; constructor (name, age) &#123; super(name) this.age = age &#125;&#125;let c = new Child(&#x27;lisi&#x27;, 30)console.log(c) 静态方式 or 静态属性 12345678910111213class Parent &#123; constructor (name = &#x27;zhangsan&#x27;) &#123; this.name = name &#125; static say () &#123; console.log(`hello`) &#125;&#125;Parent.age = 30Parent.say()console.log(Parent.age) getter or setter 1234567891011121314151617class Parent &#123; constructor (name = &#x27;zhangsan&#x27;) &#123; this.name = name &#125; get longName () &#123; return &#x27;get-&#x27; + this.name &#125; set longName (name) &#123; this.name = &#x27;set-&#x27; + name &#125;&#125;let parent = new Parent(&#x27;lisi&#x27;)console.log(parent.longName)parent.longName = &#x27;zhangsan&#x27;console.log(parent.longName) PromisePromise对象表示异步操作的最终完成(或失败)及其产生的值。主要是用在异步编程，A函数执行完成后执行B。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172let promise1 = new Promise((resolve, reject) =&gt; &#123; // console.log(&#x27;defined proimse&#x27;) setTimeout(resolve, 1000, &#x27;foo&#x27;)&#125;)promise1.then((v) =&gt; &#123; console.log(&#x27;执行成功，值为：&#x27;,v)&#125;).catch(e =&gt; &#123; console.log(e)&#125;)//封装function request (url) &#123; return new Promise((resolve, reject) =&gt; &#123; const xhr = new XMLHttpRequest() xhr.open(&#x27;GET&#x27;, url) xhr.onload = () =&gt; resolve(xhr.responseText) xhr.onerror = () =&gt; reject(xhr.statusText) xhr.send() &#125;)&#125;request(&#x27;http:/www.baidu.com&#x27;) .then(v =&gt; &#123; console.log(v) &#125;).catch(e =&gt; &#123; console.error(e)&#125;)// promise allfunction loadImg (src) &#123; return new Promise((resolve, reject) =&gt; &#123; let img = new Image() img.src = src img.onload = () =&gt; &#123; resolve(img) &#125; img.onerror = (e) =&gt; &#123; reject(e) &#125; &#125;)&#125;function showImgs (imgs) &#123; imgs.forEach(img =&gt; &#123; console.log(img) &#125;)&#125;//全部相应Promise.all([ loadImg(&#x27;http://1.jpg&#x27;), loadImg(&#x27;http://2.jpg&#x27;), loadImg(&#x27;http://3.jpg&#x27;)]).then(imgs =&gt; &#123; showImgs(imgs)&#125;).catch(e =&gt; &#123; console.error(e)&#125;)//其中一个相应Promise.race([ loadImg(&#x27;http://1.jpg&#x27;), loadImg(&#x27;http://2.jpg&#x27;), loadImg(&#x27;http://3.jpg&#x27;)]).then(imgs =&gt; &#123; showImgs(imgs)&#125;).catch(e =&gt; &#123; console.error(e)&#125;) IteratorIterator接口用于统一读取数据集合的操作，如Array,Map,Set等。 123456789101112131415161718192021222324252627282930313233343536//使用let arr = [&#x27;hello&#x27;, &#x27;world&#x27;]let map = arr[Symbol.iterator]()console.log(map.next())console.log(map.next())console.log(map.next())//for oflet arr = [&#x27;hello&#x27;, &#x27;world&#x27;]for (const value of arr) &#123; console.log(&#x27;value&#x27;, value)&#125;// custom iteratorlet obj = &#123; start: [1, 3, 2], end: [7, 8, 9], [Symbol.iterator]() &#123; let self = this let index = 0 let arr = self.start.concat(self.end) let len = arr.length return &#123; next() &#123; return &#123; value: arr[index++], done: !(index &lt; len) &#125; &#125; &#125; &#125;&#125;for (let key of obj) &#123; console.log(key)&#125; GeneratorGenerator由生成器函数返回，它符合iterable协议和迭代器协议,主要是解决异步编程，使用yield关键字，调用next进行执行一下步代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778//基本使用function* gen() &#123; yield 1 yield 2 yield 3&#125;let g = gen()console.log(g.next())console.log(g.next())console.log(g.next())console.log(g.next())// 使用generator实现iteratorlet obj = &#123;&#125;obj[Symbol.iterator] = function* () &#123; yield 1 yield 2 yield 3&#125;for (const value of obj) &#123; console.log(value)&#125;// 状态机let state = function* () &#123; while (1) &#123; yield &#x27;A&#x27; yield &#x27;B&#x27; yield &#x27;C&#x27; &#125;&#125;let status = state()console.log(status.next())console.log(status.next())console.log(status.next())console.log(status.next())console.log(status.next())console.log(status.next())//asynclet state = async function () &#123; while (1) &#123; await &#x27;A&#x27; await &#x27;B&#x27; await &#x27;C&#x27; &#125;&#125;let status = state()console.log(status.next())console.log(status.next())console.log(status.next())console.log(status.next())console.log(status.next())console.log(status.next())//实例 - 长轮询let ajax = function * () &#123; yield new Promise((resolve, reject) =&gt; &#123; setTimeout(() =&gt; &#123; resolve(&#123; code: 0 &#125;) &#125;, 200) &#125;)&#125;let pull = function () &#123; let generator = ajax() let step = generator.next() step.value.then((d) =&gt; &#123; if (d.code != 0) &#123; setTimeout(function () &#123; console.log(&#x27;wait&#x27;) pull() &#125;, 1000) &#125; else &#123; console.log(d) &#125; &#125;)&#125;pull() DecoratorDecorator 是用来修改类行为，是函数、类、修改行为。Decorator仅当前类中有用。 npm install babel-plugin-transform-decorators-legacy 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758//定义类型属性或方法 let readonly = function (target, name, descriptor) &#123; descriptor.writable = false return descriptor &#125; class Test &#123; @readonly time() &#123; return &#x27;2018-04-19&#x27; &#125; &#125; let test = new Test() console.log(test.time()) /* test.time = function () &#123; console.log(&#x27;reset time method&#x27;) &#125; */ //类修饰符 let typename = function (target, name, descriptor) &#123; target.myname = &#x27;hello&#x27; &#125; @typename class Test &#123;&#125; console.log(&#x27;类修饰符&#x27;, Test.myname)// 实例 - 页面日志收集let log = (type) =&gt; &#123; return function (target, name, descriptor) &#123; console.dir(descriptor) let src_method = descriptor.value; descriptor.value = (...args) =&gt; &#123; src_method.apply(target, args); console.log(`log $&#123;type&#125;`) &#125; &#125;&#125;class Page &#123; @log(&#x27;show&#x27;) show() &#123; console.log(&#x27;show page&#x27;) &#125; @log(&#x27;click&#x27;) click(count) &#123; console.log(&#x27;click page:&#x27;,count) &#125;&#125;let page = new Page()page.show()page.click(1)page.click(2) Module模块是自动运行在严格模式下并且没有办法退出运行的JS代码。与共享一切架构相反的是，在模块顶部创建的变量不会自动被添加到全局共享作用域，这个变量仅在模块的顶级作用域中存在，而且模块必须导出一些外部代码可以访问的元素，如变量或函数。模块也可以从其他模块导入绑定。 另外两个模块的特性与作用域关系不大，但也很重要。首先，在模块的顶部，this的值是undefined；其次，模块不支持HTML风格的代码注释，这是从早期浏览器残余下来的JS特性 脚本，也就是任何不是模块的JS代码，则缺少这些特性。模块和其他JS代码之间的差异可能乍一看不起眼，但是它们代表了JS代码加载和求值的一个重要变化。模块真正的魔力所在是仅导出和导入需要的绑定，而不是将所用东西都放到一个文件。只有很好地理解了导出和导入才能理解模块与脚本的区别 导出 12345678910111213141516171819202122232425262728293031323334//导出变量export let A = 123//导出方法export function test () &#123; console.log(&#x27;test&#x27;)&#125;//导出类export class Hello &#123; test () &#123; console.log(&#x27;class&#x27;) &#125;&#125;//导出默认类export default class Hello2 &#123; test() &#123; console.log(&#x27;test2&#x27;) &#125;&#125;//统一导出，由import进行定义名称let A = 123let test = () =&gt; &#123; console.log(&#x27;fun test&#x27;)&#125;class Hello &#123; test() &#123; console.log(&#x27;hello class&#x27;) &#125;&#125;export default &#123; A, test, Hello&#125; 导入 123456789//根据导出的名称进行导入import &#123; Hello, A, test &#125; from &#x27;./16-module_export&#x27;//导入默认项import Hello2 from &#x27;./16-module_export&#x27;//导入全部，但默认项不会此导入别名中import * as e from &#x27;./16-module_export&#x27;//导入默认项为export defaultimport m from &#x27;./16-module_export&#x27;","tags":[{"name":"js","slug":"js","permalink":"https://hhqqnu.github.io/tags/js/"}]},{"title":"消息队列之Kafka","date":"2017-09-06T12:53:41.000Z","path":"2017/09/06/消息队列之Kafka/","text":"认识KafKa什么是KafKakafka是一种高吞吐量的分布式发布订阅消息系统，有如下特性： 通过O(1)的磁盘数据结构提供消息的持久化，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能。 高吞吐量：即使是非常普通的硬件kafka也可以支持每秒数十万的消息。 支持通过kafka服务器和消费机集群来分区消息。 支持Hadoop并行数据加载。 Kafka的目的是提供一个发布订阅解决方案，它可以处理消费者规模的网站中的所有动作流数据。 这种动作（网页浏览，搜索和其他用户的行动）是在现代网络上的许多社会功能的一个关键因素。 这些数据通常是由于吞吐量的要求而通过处理日志和日志聚合来解决。 对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。kafka的目的是通过Hadoop的并行加载机制来统一线上和离线的消息处理，也是为了通过集群机来提供实时的消费。 在Kafka有几个比较重要的概念： broker 用于标识每一个Kafka服务，当然同一台服务器上可以开多个broker,只要他们的broker id不相同即可 Topic 消息主题，从逻辑上区分不同的消息类型 Partition 用于存放消息的队列，存放的消息都是有序的，同一主题可以分多个partition，如分多个partiton时，同样会以如partition1存放1,3,5消息,partition2存放2,4,6消息。 Produce 消息生产者，生产消息，可指定向哪个topic，topic哪个分区中生成消息。 Consumer 消息消费者，消费消息，同一消息只能被同一个consumer group中的consumer所消费。consumer是通过offset进行标识消息被消费的位置。当然consumer的个数取决于此topic所划分的partition，如同一group中的consumer个数大于partition的个数，多出的consumer将不会处理消息。 分布式搭建KafKa服务器资源： 服务器名称 操作系统 IP地址 Server-01 Centeos 6.5 172.16.128.144 Server-02 Centeos 6.5 172.16.128.145 Server-03 Centeos 6.5 172.16.128.146 在每台服务器上提前安装JDK 1.8 使用命令行Java -version查看是否成功 Kafka是通过Zookeeper进行管理群集，在每台服务器上先安装zookeeper。 搭建Zookeeperzookeeper下载： 1wget https://mirrors.cnnic.cn/apache/zookeeper/zookeeper-3.3.6/zookeeper-3.3.6.tar.gz 解压zookeeper: 12tar -xvf zookeeper-3.3.6.tar.gzmv zookeeper-3.3.6 zookeeper 修改配置文件： 12cp conf/zoo_sample.cfg conf/zoo.cfgvim conf/zoo.cfg 配置文件参数说明:tickTime这个时间是作为zookeeper服务器之间或客户端与服务器之间维持心跳的时间间隔,也就是说每个tickTime时间就会发送一个心跳。 initLimit这个配置项是用来配置zookeeper接受客户端（这里所说的客户端不是用户连接zookeeper服务器的客户端,而是zookeeper服务器集群中连接到leader的follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。 当已经超过10个心跳的时间（也就是tickTime）长度后 zookeeper 服务器还没有收到客户端的返回信息,那么表明这个客户端连接失败。总的时间长度就是 10*2000=20秒。 syncLimit这个配置项标识leader与follower之间发送消息,请求和应答时间长度,最长不能超过多少个tickTime的时间长度,总的时间长度就是5*2000=10秒。 dataDir顾名思义就是zookeeper保存数据的目录,默认情况下zookeeper将写数据的日志文件也保存在这个目录里； clientPort这个端口就是客户端连接Zookeeper服务器的端口,Zookeeper会监听这个端口接受客户端的访问请求； server.A=B:C:D中的A是一个数字,表示这个是第几号服务器,B是这个服务器的IP地址，C第一个端口用来集群成员的信息交换,表示这个服务器与集群中的leader服务器交换信息的端口，D是在leader挂掉时专门用来进行选举leader所用的端口。 创建ServerID标识:除了修改zoo.cfg配置文件外,zookeeper集群模式下还要配置一个myid文件,这个文件需要放在dataDir目录下。 这个文件里面有一个数据就是A的值（该A就是zoo.cfg文件中server.A=B:C:D中的A）,在zoo.cfg文件中配置的dataDir路径中创建myid文件。 在172.16.128.144服务器上创建myid文件，并设置为1，同时与zoo.cfg文件里面的server.1对应，如下： 1echo &quot;1&quot; &gt; /root/applicaton/zookeeper_app/zookeeper/data/myid 将上述配置好的文件通scp命令分别复制到server-02,server-03上面 1234567scp /root/application/zookeeper_app/zookeeper root@172.16.128.145 /root/application/zookeeper_app/scp /root/application/zookeeper_app/zookeeper root@172.16.128.146 /root/application/zookeeper_app/#修改server-02 myid文件echo &quot;2&quot; &gt; /root/application/zookeeper_app/zookeeper/data/myid#个性server-03 myid文件echo &quot;3&quot; &gt; /root/application/zookeeper_app/zookeeper/data/myid 启动各服务器上的zookeeper: 1../zookeeper/bin/zkServer.sh start &amp; 查看zookeeper状态： 1../zookeeper/bin/zkServer.sh status 查看状态会看到其中一台服务器的mode为leader，其他两台为follower 搭建Kafkakafka下载: 1wget https://www.apache.org/dyn/closer.cgi?path=/kafka/0.11.0.0/kafka_2.11-0.11.0.0.tgz 解压kafka: 12tar -xvf kafka_2.11-0.11.0.0.tgzmv kafka_2.11-0.11.0.0 kafka 修改配置文件： 12345678910111213141516171819vim config/server.properties#server-01broker.id=1listeners=PLAINTEXT://172.16.128.144:9092log.dirs=/root/application/kafka_app/kafka/kafka-logsnum.partitions = 2zookeeper.connect=172.16.128.144:2181,172.16.128.145:2181,172.16.128.146:2181#server-02broker.id=2listeners=PLAINTEXT://172.16.128.145:9092log.dirs=/root/application/kafka_app/kafka/kafka-logsnum.partitions = 2zookeeper.connect=172.16.128.144:2181,172.16.128.145:2181,172.16.128.146:2181#server-03broker.id=3listeners=PLAINTEXT://172.16.128.146:9092log.dirs=/root/application/kafka_app/kafka/kafka-logsnum.partitions = 2zookeeper.connect=172.16.128.144:2181,172.16.128.145:2181,172.16.128.146:2181 配置文件参数说明：broker.id broker唯一标识listeners kafka监听IP及安全方式log.dirs 日志存储num.partitions 创建topic时默认partition数量zookeeper.connect zookeeper服务器地址 启动各服务器kafka： 1../kafka/bin/kafka-server-start.sh ../config/server.properties &amp; 查看kafka状态可以通过命令行执行jps或pa -aux 或netstat -ntlp利用netstat -ntlp会看服务器监听的9092接口。 使用KafKaKafka Consoletopic创建 1./bin/kafka-topics.sh --zookeeper 172.16.128.144:2181,172.16.128.145:2181,172.16.128.146:2181 --create --topic my-test-topic --partitions 5 --replication-factor 1 查看 1../kafka/bin/kafka-topic --list --zookeeper 172.16.128.144:9092 Produce1./bin/kafka-console-producer.sh --topic my-test-topic --broker-list 172.16.128.144:9092,172.16.128.145:9092,172.16.128.146:9092 Consumer1./bin/kafka-console-consumer.sh --bootstrap-server 172.16.128.144:9092,172.16.128.145:9092,172.16.128.146:9092 --topic my-test-topic --from-beginning Native JAVA API创建Java Maven项目.在Pom文件中引入”kafka-clients” jar包 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &lt;version&gt;0.11.0.0&lt;/version&gt;&lt;/dependency&gt; Produce1234567891011121314151617181920private static String topic = &quot;my-test-topic&quot;;private Properties createProps() &#123; Properties props = new Properties(); props.put(&quot;bootstrap.servers&quot;, &quot;172.16.128.144:9092,172.16.128.145:9092,172.16.128.146:9092&quot;); props.put(&quot;acks&quot;, &quot;all&quot;); props.put(&quot;retries&quot;, 0); props.put(&quot;batch.size&quot;, 16384); props.put(&quot;linger.ms&quot;, 1); props.put(&quot;buffer.memory&quot;, 33554432); props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); return props;&#125;public void send() &#123; Producer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(createProps()); for (int i = 0; i &lt; 10; i++) &#123; producer.send(new ProducerRecord&lt;String, String&gt;(topic, &quot;key:&quot; + Integer.toString(i), &quot;value:&quot; + Integer.toString(i))); &#125; producer.close();&#125; Consumer1234567891011121314151617181920212223242526272829private static String topic = &quot;my-test-topic&quot;;public void receiveTest() &#123; Properties props = new Properties(); props.put(&quot;bootstrap.servers&quot;, &quot;172.16.128.144:9092,172.16.128.145:9092,172.16.128.146:9092&quot;); props.put(&quot;group.id&quot;, &quot;test&quot;); props.put(&quot;enable.auto.commit&quot;, &quot;true&quot;); props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;); props.put(&quot;session.timeout.ms&quot;, &quot;30000&quot;); props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;String, String&gt;(props); consumer.subscribe(Collections.singletonList(topic)); try &#123; while (true) &#123; ConsumerRecords&lt;String, String&gt; records = consumer.poll(Long.MAX_VALUE); for (TopicPartition partition : records.partitions()) &#123; List&lt;ConsumerRecord&lt;String, String&gt;&gt; partitionRecords = records.records(partition); for (ConsumerRecord&lt;String, String&gt; record : partitionRecords) &#123; System.out.println(record.offset() + &quot;: &quot; + record.value()); &#125; long lastOffset = partitionRecords.get(partitionRecords.size() - 1).offset(); consumer.commitSync(Collections.singletonMap(partition, new OffsetAndMetadata(lastOffset + 1))); &#125; &#125; &#125; finally &#123; consumer.close(); &#125;&#125; Spring boot KafkaSpring boot Kafka是由spring对kafka操作的一种封装，方便进行对kafka操作（Spring对Kafka的操作有spring-kaka和spring-integration-kafka,示例以spring-kafka操作kafka）。 创建spring boot项目。在pom文件内引入”spring-kafka”jar 12345678910111213141516171819&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-kafka.version&gt;1.2.2.RELEASE&lt;/spring-kafka.version&gt;&lt;/properties&gt;&lt;!-- spring-kafka --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-kafka.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &lt;artifactId&gt;spring-kafka-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-kafka.version&#125;&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 配置spring application.yml123456789spring: kafka: bootstrap-servers: 172.16.128.144:9092,172.16.128.145:9092,172.16.128.146:9092 template: default-topic: my-test-topic consumer: group-id: mytesttopicgroup listener: concurrency: 5 Produce添加produce配置java文件及处理文件。 SenderConfig.java 1234567891011121314151617181920212223242526272829@Configurationpublic class SenderConfig &#123; @Value(&quot;$&#123;spring.kafka.bootstrap-servers&#125;&quot;) private String bootstrapServers; @Bean public Map&lt;String, Object&gt; producerConfigs() &#123; Map&lt;String, Object&gt; props = new HashMap&lt;&gt;(); props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers); props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class); props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class); return props; &#125; @Bean public ProducerFactory&lt;String, String&gt; producerFactory() &#123; return new DefaultKafkaProducerFactory&lt;&gt;(producerConfigs()); &#125; @Bean public KafkaTemplate&lt;String, String&gt; kafkaTemplate() &#123; return new KafkaTemplate&lt;&gt;(producerFactory()); &#125; @Bean public Sender sender() &#123; return new Sender(); &#125; Sender.java 123456789101112public class Sender &#123; private static final Logger LOGGER = LoggerFactory.getLogger(Sender.class); @Autowired private KafkaTemplate&lt;String, String&gt; kafkaTemplate; public void send(String topic, String data) &#123; kafkaTemplate.send(topic, data); &#125;&#125; Consumer添加consumer配置java文件及处理文件。 ReceiverConfig.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Configuration@EnableKafkapublic class ReceiverConfig &#123; @Value(&quot;$&#123;spring.kafka.bootstrap-servers&#125;&quot;) private String bootstrapServers; @Value(&quot;$&#123;spring.kafka.consumer.group-id&#125;&quot;) private String groupId; @Value(&quot;$&#123;spring.kafka.listener.concurrency&#125;&quot;) private int concurrency; @Bean public Map&lt;String, Object&gt; consumerConfigs() &#123; Map&lt;String, Object&gt; props = new HashMap&lt;&gt;(); props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers); props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId); return props; &#125; @Bean public ConsumerFactory&lt;String, String&gt; consumerFactory() &#123; return new DefaultKafkaConsumerFactory&lt;&gt;(consumerConfigs()); &#125; @Bean public ConcurrentKafkaListenerContainerFactory&lt;String, String&gt; kafkaListenerContainerFactory() &#123; ConcurrentKafkaListenerContainerFactory&lt;String, String&gt; factory = new ConcurrentKafkaListenerContainerFactory&lt;&gt;(); factory.setConsumerFactory(consumerFactory()); factory.setConcurrency(concurrency); return factory; &#125; @Bean public Receiver receiver()&#123; return new Receiver(); &#125;&#125; Receiver.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class Receiver &#123; @Autowired private MessageHandle messageHandle; private static final Logger LOGGER = LoggerFactory.getLogger(Receiver.class); private CountDownLatch latch0 = new CountDownLatch(5); private CountDownLatch latch1 = new CountDownLatch(5); private CountDownLatch latch2 = new CountDownLatch(5); private CountDownLatch latch3 = new CountDownLatch(5); private CountDownLatch latch4 = new CountDownLatch(5); @KafkaListener(id = &quot;id0&quot;, topicPartitions = &#123;@TopicPartition(topic = &quot;$&#123;spring.kafka.template.default-topic&#125;&quot;, partitions = &#123;&quot;0&quot;&#125;)&#125;) public void listenPartition0(String message) &#123; LOGGER.info(&quot;received message=&#x27;&#123;&#125;&#x27;&quot;, message); LOGGER.info(&quot;thread ID:&quot; + Thread.currentThread().getId()); latch0.countDown(); &#125; @KafkaListener(id = &quot;id1&quot;, topicPartitions = &#123;@TopicPartition(topic = &quot;$&#123;spring.kafka.template.default-topic&#125;&quot;, partitions = &#123;&quot;1&quot;&#125;)&#125;) public void listenPartition1(String message) &#123; LOGGER.info(&quot;received message=&#x27;&#123;&#125;&#x27;&quot;, message); LOGGER.info(&quot;thread ID:&quot; + Thread.currentThread().getId()); latch1.countDown(); &#125; @KafkaListener(id = &quot;id2&quot;, topicPartitions = &#123;@TopicPartition(topic = &quot;$&#123;spring.kafka.template.default-topic&#125;&quot;, partitions = &#123;&quot;2&quot;&#125;)&#125;) public void listenPartition2(String message) &#123; LOGGER.info(&quot;received message=&#x27;&#123;&#125;&#x27;&quot;, message); LOGGER.info(&quot;thread ID:&quot; + Thread.currentThread().getId()); latch2.countDown(); &#125; @KafkaListener(id = &quot;id3&quot;, topicPartitions = &#123;@TopicPartition(topic = &quot;$&#123;spring.kafka.template.default-topic&#125;&quot;, partitions = &#123;&quot;3&quot;&#125;)&#125;) public void listenPartition3(String message) &#123; LOGGER.info(&quot;received message=&#x27;&#123;&#125;&#x27;&quot;, message); LOGGER.info(&quot;thread ID:&quot; + Thread.currentThread().getId()); latch3.countDown(); &#125; @KafkaListener(id = &quot;id4&quot;, topicPartitions = &#123;@TopicPartition(topic = &quot;$&#123;spring.kafka.template.default-topic&#125;&quot;, partitions = &#123;&quot;4&quot;&#125;)&#125;) public void listenPartition4(String message) &#123; LOGGER.info(&quot;received message=&#x27;&#123;&#125;&#x27;&quot;, message); LOGGER.info(&quot;thread ID:&quot; + Thread.currentThread().getId()); latch4.countDown(); &#125;&#125; 总结到此kafka的搭建到使用都已结束，在消费kafka消息时，建议使用spring boot + spring kafka。由于spring boot打包部署比较方便，同一台机器上可以开多个spring boot也就是开多个进程的consumer。如不想开多个进程处理，在spring kafka 中@KafkaListener注解可针对不同的topic，不同的partition消费，也可开不同的线程进行消费kafka。 kafka还有很多需要学习的地方，如：kafka-stream,topic的管理，topic的消息分布情况，查看当前有多少个consumer group，每个consumer的offset是多少等等。","tags":[{"name":"消息队列","slug":"消息队列","permalink":"https://hhqqnu.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"kafka","slug":"kafka","permalink":"https://hhqqnu.github.io/tags/kafka/"}]},{"title":"markdown pad 2 导出html 自定义目录","date":"2017-08-01T12:35:15.000Z","path":"2017/08/01/markdown-pad-2-导出html-自定义目录/","text":"程序员使用markdown进行编写api或其他文档，是常用的事。在windows上markdown客户端工具“markdown pad2“应该是首选了，功能比较完善，但在导出文档为HTML时，工具确不支持目录导出。还好此工具为我们提供了自定义Html样式操作(也就是在生成的HTML文档的Head中添加自定义代码)，可以利用这一点进行导出自己想要的目录。 添加自定义HTML样式操作如下： 步骤一 步骤二 自定义代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394&lt;style&gt; .tocDiv &#123; position: fixed; width: 28%; float: left; margin-right: 2%; min-width: 267px; background-color:#ffffff; &#125; .tocDiv ul &#123; list-style: none; border: 1px solid rgb(204, 204, 204); padding-left: 0px; &#125; .tocDiv ul li &#123; line-height: 30px; &#125; .tocDiv ul a &#123; text-decoration: none; &#125; .tocDiv ul a:hover &#123; text-decoration: none; color: red; &#125; body &#123; max-width: 100% !important; min-width: 960px !important; &#125; .contentDiv &#123; width: 70%; float: right; &#125; &lt;&#x2F;style&gt; &lt;script&gt; &#x2F;&#x2F; 类似Java的hash生成方式，为一段文字生成一段基本不会重复的数字 function _hashCode(txt) &#123; var hash &#x3D; 0; if (txt.length &#x3D;&#x3D; 0) return hash; for (i &#x3D; 0; i &lt; txt.length; i++) &#123; char &#x3D; txt.charCodeAt(i); hash &#x3D; ((hash &lt;&lt; 5) - hash) + char; hash &#x3D; hash &amp; hash; &#x2F;&#x2F; Convert to 32bit integer &#125; return hash; &#125; function buildToc() &#123; var outline &#x3D; document.createElement(&quot;ul&quot;); outline.setAttribute(&quot;id&quot;, &quot;outline-list&quot;); outline.style.cssText &#x3D; &quot;border: 1px solid #ccc;&quot;; var headers &#x3D; document.querySelectorAll(&#39;h1,h2,h3,h4,h5,h6&#39;); for (var i &#x3D; 0; i &lt; headers.length; i++) &#123; var header &#x3D; headers[i]; if (i &#x3D;&#x3D; 0) &#123; window.document.title &#x3D; header.textContent; &#125; var hash &#x3D; _hashCode(header.textContent); &#x2F;&#x2F; MarkdownPad2无法为中文header正确生成id，这里生成一个 header.setAttribute(&quot;id&quot;, header.tagName + hash); &#x2F;&#x2F; 找出它是H几，为后面前置空格准备 var prefix &#x3D; parseInt(header.tagName.replace(&#39;H&#39;, &#39;&#39;), 10); outline.appendChild(document.createElement(&quot;li&quot;)); var a &#x3D; document.createElement(&quot;a&quot;); &#x2F;&#x2F; 为目录项设置链接 a.setAttribute(&quot;href&quot;, &quot;#&quot; + header.tagName + hash) &#x2F;&#x2F; 目录项文本前面放置对应的空格 a.innerHTML &#x3D; new Array(prefix * 3).join(&#39;&amp;nbsp;&#39;) + header.textContent; outline.lastChild.appendChild(a); &#125; return outline; &#125; window.onload &#x3D; function() &#123; var tocUl &#x3D; buildToc(); var bodyTag &#x3D; document.getElementsByTagName(&#39;body&#39;)[0]; var bodyTagHtml &#x3D; bodyTag.innerHTML; var tocDiv &#x3D; document.createElement(&#39;div&#39;); tocDiv.className &#x3D; &#39;tocDiv&#39;; tocDiv.appendChild(tocUl); var contentDiv &#x3D; document.createElement(&#39;div&#39;); contentDiv.className &#x3D; &#39;contentDiv&#39;; contentDiv.innerHTML &#x3D; bodyTagHtml; bodyTag.innerHTML &#x3D; &#39;&#39;; bodyTag.appendChild(tocDiv); bodyTag.appendChild(contentDiv); &#125; &lt;&#x2F;script&gt; 最终目录效果（未截全）：","tags":[{"name":"markdown","slug":"markdown","permalink":"https://hhqqnu.github.io/tags/markdown/"}]},{"title":"初始VueJs视频教程","date":"2017-05-14T13:17:28.000Z","path":"2017/05/14/初始VueJs视频教程/","text":"从未通过录制视频撰写博客，抱着试试看的态度录制了下面的视频（第一次录制，说得不好，请观看海涵）： 观看地址","tags":[{"name":"javascript","slug":"javascript","permalink":"https://hhqqnu.github.io/tags/javascript/"}]},{"title":"Html5大文件上传","date":"2017-02-08T13:22:48.000Z","path":"2017/02/08/Html5大文件上传/","text":"文件上传已是老生常谈了。文件上传，原始的方法有： form表单提交。 通过iframe+form表单进行模拟异步上传。 由于Http协议的限制，在处理大文件上传会存在超时的现象。在旧的浏览器中是无法读取文件二进制数据。无法将文件以分片的方式进行上传。 最近由于产品需求，在不安装插件的情况下上传大文件（百度webuploader开源项目做得已经很不错了，但在秒传和低版本浏览器上使用flash不太符合要求）。于是重新撸了一把html大文件上传（整个项目是spring boot搭建)。 先来简单的介绍用了哪些javascript类库 File 文件 FileRead 读取文件 XMLHttpRequest 上传文件 FormData 上传时所需数据 spark-md5 用于MD5 HASH值计算(第三方插件） 本次实现拖拽上传，用到了页面拖拽事件：ondragenter,ondragleave,ondragover,ondrop 实现思路 建立一个上传队列。 通过拖拽获取得到文件。 为每个文件添加各自的上传方法。 秒传判断 上传分片文件 （后台存放临时分片文件） 合并文件 添加文件到上传队列。 最终效果 代码部分html123456789101112131415161718192021222324252627282930313233343536373839404142&lt;!doctype html&gt;&lt;html lang=&quot;zh-CN&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;ie=edge&quot;&gt; &lt;title&gt;&lt;/title&gt; &lt;style&gt; * &#123; margin: 0; padding: 0; &#125; .dropZone &#123; width: 300px; height: 200px; line-height: 200px; margin: 10px auto; border: 2px dashed #ccc; color: #cccccc; text-align: center; &#125; .dropZone.dropOver &#123; border-color: #000; color: #000; &#125; button &#123; margin-right: 10px; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;div id=&quot;dropZone&quot; class=&quot;dropZone&quot;&gt; drop file&lt;/div&gt;&lt;div&gt; &lt;h1&gt;fileList&lt;/h1&gt; &lt;ul id=&quot;uploadList&quot;&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; MD51234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768//md5 !function (win, sparkMD5) &#123; let Md5File = function (options) &#123; this._init(options); this.fileMd5Hash(); &#125;; Md5File.prototype = &#123; _init: function (opts) &#123; this.file = opts.file; this.fileSliceLength = opts.fileSliceLength || 1024 * 1024; this.chunks = opts.chunks || 10; this.chunkSize = parseInt(this.file.size / this.chunks, 10); this.currentChunk = 0; this.md5Complete = opts.md5Complete; this.spark = new sparkMD5.ArrayBuffer(); this.sparks = []; &#125;, fileMd5Hash: function () &#123; this._readFileMd5Hash(); &#125;, _readFileMd5Hash: function () &#123; let self = this; console.group(&quot;currentChunk:&quot;, self.currentChunk, &#x27;chunkSize&#x27;, self.chunkSize, &#x27;fileSize:&#x27;, self.file.size, &#x27;fileSliceLength:&#x27;, self.fileSliceLength); let start = self.currentChunk * self.chunkSize; let end = Math.min(start + self.chunkSize, self.file.size); if (self.currentChunk &lt; self.chunks) &#123; end = start + self.fileSliceLength; &#125; console.log(&#x27;start:&#x27;, start, &#x27;end:&#x27;, end, &#x27;get chunk:&#x27;, end - start); console.groupEnd(); let fileReader = new FileReader(); fileReader.onload = function (e) &#123; let spark = new sparkMD5.ArrayBuffer(); spark.append(e.target.result); let tempSpark = spark.end(); console.log(tempSpark); self.sparks.push(tempSpark); self.currentChunk++; if (self.currentChunk &lt; self.chunks) &#123; self._readFileMd5Hash(); &#125; else &#123; let endSparkStr = self.sparks.join(&#x27;&#x27;); console.log(endSparkStr); self.md5Complete &amp;&amp; typeof self.md5Complete == &#x27;function&#x27; &amp;&amp; self.md5Complete(endSparkStr); &#125; /* self.spark.append(e.target.result); self.currentChunk++; if (self.currentChunk &lt; self.chunks) &#123; self._readFileMd5Hash(); &#125; else &#123; self.md5Complete &amp;&amp; typeof self.md5Complete == &#x27;function&#x27; &amp;&amp; self.md5Complete(self.spark.end()); &#125;*/ &#125;; fileReader.readAsArrayBuffer(self.file.slice(start, end)); &#125; &#125;; win.md5File = function (options) &#123; return new Md5File(options); &#125; &#125;(window, SparkMD5); 上传类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179//文件上传类 !function (win) &#123; &#x27;use strict&#x27;; let FileUpload = function (options) &#123; if (typeof options != &#x27;object&#x27;) &#123; throw Error(&#x27;options not is object&#x27;); &#125; this.init(options); if (this.autoUpload) &#123; this.start(); &#125; &#125;; FileUpload.prototype = &#123; init: function (opts) &#123; this.file = opts.file; this.url = opts.url; this.compileFileUrl = opts.compileFileUrl; this.autoUpload = opts.autoUpload || 0; this.chunk = opts.chunk || (10 * 1024 * 1024); this.chunks = Math.ceil(this.file.size / this.chunk); this.currentChunk = 0; this.taskName = opts.taskName || win.uuid(); this.isUploading = false; this.isUploaded = false; this.upProgress = opts.upProgress; //上传进度 this.upComplete = opts.upComplete; //上传完成 this.timeHandle = opts.timeHandle; // 时间处理 this.timeInfo = &#123; h: 0, m: 0, s: 0 &#125;; this.md5FileHash = null; this.remoteMd5FileHash = opts.remoteMd5FileHash; //远程对比文件,是http请求函数 this.isSendCompleteFile = opts.isSendCompleteFile || 0; //是否发送合并文件指令 return this; &#125;, start: function () &#123; let self = this; //秒传判断 if (!self.md5FileHash) &#123; win.md5File(&#123; file: self.file, md5Complete: function (hash) &#123; self.md5FileHash = hash; //后台进行判断hash值是否一致，如何一致则直接上传完成。 if (self.remoteMd5FileHash &amp;&amp; typeof self.remoteMd5FileHash == &#x27;function&#x27;) &#123; self.remoteMd5FileHash(self.file.name, self.md5FileHash, function (result) &#123; if (result) &#123; self.initInterval(); self.isUploaded = true; self.isUploading = true; self.upProgress &amp;&amp; typeof self.upProgress == &#x27;function&#x27; &amp;&amp; self.upProgress(1, 1); if (self.upComplete &amp;&amp; typeof self.upComplete == &#x27;function&#x27;) &#123; if (self.time) win.clearInterval(self.time); self.upComplete(); &#125; &#125; else &#123; if (!self.isUploading &amp;&amp; !self.isUploaded) &#123; self.initInterval(); self._upload(); &#125; &#125; &#125;); &#125; &#125; &#125;); &#125; else &#123; //上传 if (!self.isUploading &amp;&amp; !self.isUploaded) &#123; self.initInterval(); self._upload(); &#125; &#125; &#125;, pause: function () &#123; if (this.isUploading) &#123; this.xhr &amp;&amp; this.xhr.abort(); this.isUploading = false; if (this.time) win.clearInterval(this.time); &#125; &#125;, _initXhr: function () &#123; let self = this; self.xhr = new XMLHttpRequest(); self.xhrLoad = function () &#123; if (self.end == self.file.size) &#123; self.isUploaded = true; if (self.upComplete &amp;&amp; typeof self.upComplete == &#x27;function&#x27;) &#123; if (self.time) win.clearInterval(self.time); self.upComplete(); &#125; self.isSendCompleteFile &amp;&amp; self.compileFile(); &#125; else &#123; if (self.upProgress &amp;&amp; typeof self.upProgress == &#x27;function&#x27;) &#123; self.upProgress((self.currentChunk + 1), self.chunks); &#125; self.currentChunk++; self._upload(); &#125; &#125;; self.xhrError = function () &#123; console.log(&#x27;xhr error&#x27;); &#125;; self.xhrAbort = function () &#123; console.log(&#x27;xhr abort&#x27;); &#125;; self.xhr.onload = this.xhrLoad; self.xhr.onerror = this.xhrError; self.xhr.onabort = this.xhrAbort; &#125;, _upload: function () &#123; let self = this; self.isUploading = true; self._initXhr(); self.xhr.open(&#x27;POST&#x27;, self.url); //计算上传开始位置或结束位置 self.begin = self.currentChunk * self.chunk; self.end = Math.min((self.begin + self.chunk), self.file.size); let blob = self.file.slice(self.begin, self.end, &#123;type: &#x27;text/plain&#x27;&#125;); let formData = new FormData(); let tempFileName = &#x27;temp-&#x27; + self.currentChunk + &#x27;-&#x27; + self.taskName; formData.append(&#x27;fileData&#x27;, blob, tempFileName); formData.append(&#x27;tempFileName&#x27;, tempFileName); formData.append(&#x27;taskName&#x27;, self.taskName);//用于后台进行判断如果此片已存在则进行删除。 formData.append(&#x27;fileName&#x27;, self.file.name); formData.append(&#x27;position&#x27;, self.begin); formData.append(&#x27;chunkIndex&#x27;, (self.currentChunk + 1)); formData.append(&#x27;chunks&#x27;, self.chunks); self.xhr.send(formData); &#125;, compileFile: function () &#123; let self = this; self._initXhr(); self.xhrLoad = function () &#123; console.log(self.xhr.responseText); &#125;; self.xhr.onload = self.xhrLoad; self.xhr.open(&#x27;POST&#x27;, self.compileFileUrl); let formData = new FormData(); formData.append(&quot;fileName&quot;, (self.file.name)); formData.append(&#x27;taskName&#x27;, self.taskName); self.xhr.send(formData); &#125;, initInterval: function () &#123; let self = this; if (self.time) win.clearInterval(self.time); self.time = win.setInterval(function () &#123; self.timeInfo.s++; if (self.timeInfo.s == 60) &#123; self.timeInfo.s = 0; self.timeInfo.m++; if (self.timeInfo.m == 60) &#123; self.timeInfo.m = 0; self.timeInfo.h++; &#125; &#125; self.timeHandle &amp;&amp; self.timeHandle(self.formatStr()); &#125;, 1000); &#125;, formatStr: function () &#123; let _ = this, sY = (_.timeInfo.h &lt; 10) ? &#x27;0&#x27; + _.timeInfo.h : _.timeInfo.h, sM = (_.timeInfo.m &lt; 10) ? &#x27;0&#x27; + _.timeInfo.m : _.timeInfo.m, sS = (_.timeInfo.s &lt; 10) ? &#x27;0&#x27; + _.timeInfo.s : _.timeInfo.s; return sY + &#x27;:&#x27; + sM + &#x27;:&#x27; + sS; &#125; &#125;; win.fileUpload = function (options) &#123; return new FileUpload(options); &#125;; &#125;(window); 拖拽123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156//拖拽 !function () &#123; &#x27;use strict&#x27;; let dropZone = document.querySelector(&#x27;#dropZone&#x27;); let uploadList = document.querySelector(&#x27;#uploadList&#x27;); dropZone.ondragenter = function () &#123; this.className = &#x27;dropZone dropOver&#x27;; &#125;; dropZone.ondragleave = function () &#123; this.className = &#x27;dropZone&#x27;; return false; &#125;; dropZone.ondragover = function () &#123; return false; &#125;; let upComplete = function () &#123; console.log(&#x27;file up complete&#x27;); this.progressDivIng.style.width = &#x27;100%&#x27;; &#125;; let upProgress = function (chunkIndex, chunks) &#123; console.log(&#x27;up progress:&#x27;, chunkIndex, chunks); //console.log(this.progressDivIng); this.progressDivIng.style.width = (chunkIndex / chunks) * 100 + &#x27;%&#x27;; &#125;; let timeHandle = function (timeStr) &#123; this.timeSpan.innerText = timeStr; &#125;; let remoteMd5FileHash = function (fileName, md5FileHash, callback) &#123; let xhr = new XMLHttpRequest(); xhr.onload = function () &#123; let data = xhr.responseText; callback &amp;&amp; callback(data == &#x27;ok&#x27;); &#125;; xhr.open(&#x27;POST&#x27;, &#x27;/fileHash&#x27;); let formData = new FormData(); formData.append(&quot;fileName&quot;, fileName); formData.append(&#x27;md5Hash&#x27;, md5FileHash); xhr.send(formData); &#125;; let tasks = &#123;&#125;; let uploadHandler = function (files) &#123; let x = 0; for (x; x &lt; files.length; x++) &#123; let taskName = window.uuid(); let file = files[x]; tasks[taskName] = window.fileUpload(&#123; file: files[x], url: &#x27;/upload&#x27;, compileFileUrl: &#x27;/compileFile&#x27;, autoUpload: 0, isSendCompleteFile: 1, taskName: taskName, upProgress: upProgress, upComplete: upComplete, timeHandle: timeHandle, remoteMd5FileHash: remoteMd5FileHash &#125;); let li = document.createElement(&#x27;li&#x27;); let startBtn = document.createElement(&#x27;button&#x27;); startBtn.innerText = &#x27;START&#x27;; startBtn.onclick = function () &#123; console.log(&#x27;start&#x27;); tasks[taskName].start(); &#125;; let endBtn = document.createElement(&#x27;button&#x27;); endBtn.innerText = &#x27;PAUSE&#x27;; endBtn.onclick = function () &#123; tasks[taskName].pause(); &#125;; let cancelBtn = document.createElement(&#x27;button&#x27;); cancelBtn.innerText = &#x27;CANCEL&#x27;; cancelBtn.onclick = function () &#123; let currentUpTask = tasks[taskName]; if (currentUpTask.isUploaded) &#123; uploadList.removeChild(document.getElementById(taskName)); &#125; else &#123; //TODO:向后台发送取消请求 currentUpTask.pause(); let xhr = new XMLHttpRequest(); xhr.onload = function () &#123; uploadList.removeChild(document.getElementById(taskName)); &#125;; xhr.open(&#x27;GET&#x27;, &#x27;/cancel&#x27;); let formData = new FormData(); formData.append(&#x27;taskName&#x27;, taskName); xhr.send(formData); &#125; &#125;; let progressDiv = document.createElement(&#x27;div&#x27;); progressDiv.style.border = &#x27;1px solid #ccc&#x27;; progressDiv.style.height = &#x27;10px&#x27;; progressDiv.style.marginLeft = &#x27;5px&#x27;; progressDiv.style.marginRight = &#x27;5px&#x27;; let progressDivIng = document.createElement(&#x27;div&#x27;); progressDivIng.style.background = &#x27;red&#x27;; progressDivIng.style.width = &#x27;0px&#x27;; progressDivIng.style.height = &#x27;10px&#x27;; progressDiv.appendChild(progressDivIng); let timeSpan = document.createElement(&#x27;span&#x27;); timeSpan.innerText = &#x27;00:00:00&#x27;; timeSpan.style.paddingLeft = &#x27;10px&#x27;; timeSpan.style.paddingRight = &#x27;10px&#x27;; li.innerHTML = file.name; li.setAttribute(&#x27;id&#x27;, taskName); li.appendChild(timeSpan); li.appendChild(startBtn); li.appendChild(endBtn); li.appendChild(cancelBtn); li.appendChild(progressDiv); uploadList.appendChild(li); tasks[taskName].progressDivIng = progressDivIng; tasks[taskName].timeSpan = timeSpan; &#125; &#125;; let acceptFile = function (file) &#123; let rExt = /\\.\\w+$/; return rExt.exec(file.name) &amp;&amp; (file.size || file.type); &#125;; dropZone.ondrop = function (e) &#123; e.preventDefault(); let files = e.dataTransfer.files; let newFiles = []; for (let i = 0; i &lt; files.length; i++) &#123; let file = files[i]; if (acceptFile(file)) &#123; newFiles.push(file); &#125; &#125; uploadHandler(newFiles); //uploadHandler(e.dataTransfer.files); &#125;; &#125;();","tags":[{"name":"javascript","slug":"javascript","permalink":"https://hhqqnu.github.io/tags/javascript/"}]},{"title":"新年新气象","date":"2017-01-29T12:59:15.000Z","path":"2017/01/29/新年新气象/","text":"2016年已悄悄过去，2017年已悄然开始。回顾一下2016，计划了哪些，完成了哪些？ 先看下2016年计划及完成情况。 只能说完成了一半，还有很多没有完成。 对于2016的计划，不是太好，具体体现在： 从未进行过检查和总结，只是随性的完成了事。 不够完善，只做了大纲，没有时间约束等。 未考虑外界环境对计划产生的影响。 虽然计划每年都做，但2016有点草率，所以2017要合理的安排计划，不单单只有个人的提升，应包含生活的方方面面。另看待事情需长远，无论是工作还是生活，不可只看眼前。 2017新的开始，为自己加油。","tags":[{"name":"other","slug":"other","permalink":"https://hhqqnu.github.io/tags/other/"}]}]